{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Take top 50 words from Shakespeare (all 3 books) after removing all stopwords and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 words by Shakespeare:  [('haue', 448), ('ham', 337), ('thou', 312), ('shall', 300), ('lord', 293), ('come', 232), ('king', 231), ('enter', 230), ('good', 218), ('let', 217), ('thy', 202), ('caesar', 193), ('vs', 184), ('know', 176), ('thee', 174), ('would', 170), ('brutus', 162), ('like', 162), ('vpon', 162), ('bru', 153), ('well', 152), ('hath', 144), ('selfe', 143), ('man', 139), ('may', 138), ('macb', 137), ('yet', 136), ('heere', 135), ('must', 130), ('say', 130), ('tis', 129), ('th', 125), ('loue', 119), ('make', 119), ('speake', 119), ('giue', 118), ('see', 116), ('time', 115), ('sir', 114), ('night', 114), ('one', 112), ('st', 110), ('cassi', 107), ('ile', 106), ('doe', 103), ('hamlet', 100), ('go', 100), ('men', 96), ('hor', 95), ('vp', 94)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import webtext\n",
    "File = [] #Creating an empty list and adding add shakespeare files into it\n",
    "File.extend(gutenberg.words('shakespeare-caesar.txt'))\n",
    "File.extend(gutenberg.words('shakespeare-hamlet.txt'))\n",
    "File.extend(gutenberg.words('shakespeare-macbeth.txt'))\n",
    "from collections import Counter\n",
    "shake = [F.lower() for F in File] #Converting files into lowercase\n",
    "from nltk.corpus import stopwords\n",
    "filter_file = [word for word in shake if word not in stopwords.words('english')] #Removing all stopwords\n",
    "hi = []\n",
    "for h in filter_file:\n",
    "    if h.isalpha(): #Checking if all words are alphabets\n",
    "        hi.append(h)\n",
    "#print(hi)\n",
    "from collections import Counter\n",
    "shakes = Counter(hi)\n",
    "R1 = shakes.most_common(50) #Taking out the top most 50 words\n",
    "print(\"Top 50 words by Shakespeare: \",R1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take top 50 from Web_text (all the records) after removing all stopwords and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 words by Webtext:  [('girl', 2956), ('guy', 2751), ('like', 1696), ('man', 1075), ('know', 1025), ('woman', 998), ('yeah', 895), ('page', 887), ('firefox', 879), ('get', 869), ('new', 790), ('chick', 714), ('one', 700), ('oh', 682), ('open', 679), ('window', 670), ('good', 644), ('bookmarks', 598), ('teen', 587), ('well', 586), ('firebird', 583), ('cell', 577), ('right', 576), ('go', 564), ('work', 537), ('bar', 536), ('menu', 530), ('tab', 529), ('lady', 524), ('toolbar', 518), ('boy', 488), ('want', 485), ('think', 484), ('browser', 484), ('jack', 483), ('bookmark', 482), ('old', 475), ('really', 473), ('going', 460), ('download', 442), ('url', 440), ('back', 434), ('time', 432), ('black', 422), ('manager', 420), ('little', 419), ('got', 409), ('crash', 396), ('would', 392), ('button', 386)]\n"
     ]
    }
   ],
   "source": [
    "Text = [] #Creating an empty list and adding add shakespeare files into it\n",
    "Text.extend(webtext.words('firefox.txt'))\n",
    "Text.extend(webtext.words('grail.txt'))\n",
    "Text.extend(webtext.words('overheard.txt'))\n",
    "Text.extend(webtext.words('pirates.txt'))\n",
    "Text.extend(webtext.words('singles.txt'))\n",
    "Text.extend(webtext.words('wine.txt'))\n",
    "from collections import Counter\n",
    "web = [T.lower() for T in Text] #Converting files into lowercase\n",
    "from nltk.corpus import stopwords\n",
    "filter_text = [word for word in web if word not in stopwords.words('english')]\n",
    "ho = []\n",
    "for v in filter_text:\n",
    "    if v.isalpha(): #Checking if all words are alphabets\n",
    "        ho.append(v)\n",
    "from collections import Counter\n",
    "webt = Counter(ho)\n",
    "R2 = webt.most_common(50) #Taking out the top most 50 words\n",
    "print(\"Top 50 words by Webtext: \",R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show top 5 elements which are unused (used by shakespeare but not webtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 elements:  [('haue', 448), ('brutus', 162), ('vpon', 162), ('bru', 153), ('hath', 144)]\n"
     ]
    }
   ],
   "source": [
    "Result = [e for e in hi if e not in ho] #Checking only the words which are in shakespeare and not in webtext\n",
    "g = Counter(Result)\n",
    "Top5 = g.most_common(5) #Taking out the top most 5 words\n",
    "print(\"Top 5 elements: \",Top5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
